{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human Remains OSLNN - Triplet Loss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AehLane/BoneTrade-Project-OSLNN/blob/master/Human_Remains_OSLNN_Triplet_Loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWeTgO_e6Y9e",
        "colab_type": "text"
      },
      "source": [
        "# One Shot Learning with Siamese Networks\n",
        "\n",
        "Original code framework adapted from Harshvardhan Gupta, 2017 [One Shot Learning With Siamese Networks](https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch/blob/master/Siamese-networks-medium.ipynb) with code snippets from Tim Sherrat. Developed further by Alex Lane and discussed in \n",
        "Graham and Huffer, Can One-Shot Learning Identify Origins of Human Remains Shown on Social Media? \n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30S_KDoFnjZA",
        "colab_type": "text"
      },
      "source": [
        "##Running this notebook in hosted vs. local runtime environments\n",
        "\n",
        "We're assuming you have loaded this notebook with Google Colab and that you are signed into a Google account. \n",
        "\n",
        "You run each block of code in sequential order the first time through. If after having trained a network you wish to resume testing at a later date, we show you how to save your model and reload it, at the appropriate blocks.\n",
        "\n",
        "By **default**, we're assuming **you'll be using Colab's hosted runtime environment**, but if you have access to a server/cluster that you'd prefer to use instead, or would prefer to run it locally on the machine that has loaded up this Colab notebook, read on:\n",
        "\n",
        "\n",
        "*   If you want to run this notebook in a **local environment on the machine that has loaded up this Colab notebook** or if you're using **Google's Compute Engine**, you can find instructions [here](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "\n",
        "*   If you're looking to **run this notebook on another machine** and are **not** using **Google Compute Engine**, the following instructional guidelines may be of use to you.*\n",
        "\n",
        "*This is just how we've been running our local server instance. No guarantee it'll work exactly as described for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6fSt91yfkV",
        "colab_type": "text"
      },
      "source": [
        "###Our server settings and specifications\n",
        "\n",
        "Server OS: Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-74-generic x86_64)\n",
        "\n",
        "GPU: Tesla V100-PCIE-16GB\n",
        "\n",
        "Compute capability: 7.0\n",
        "\n",
        "CUDA Toolkit: 10.1\n",
        "\n",
        "CuDnn: v7.6.5 for CUDA 10.1\n",
        "\n",
        "Python: 3.6.9\n",
        "\n",
        "Tensorflow: 2.1.0\n",
        "\n",
        "PyTorch: 1.4.0\n",
        "\n",
        "Jupyter Notebook: 6.0.3\n",
        "\n",
        "Additional libraries needed: imgaug, matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wswve6o7yrMX",
        "colab_type": "text"
      },
      "source": [
        "###Steps we use to connect to our server for local runtime\n",
        "\n",
        "1.   Open cmd prompt on the machine with the open Colab notebook.\n",
        "2. We're creating a port tunnel using ssh, so choose and open port on both the client and server side; `local_port` & `server_port`.\n",
        "3.   Choose one:\n",
        "\n",
        "    3a. If your server asks for a password on ssh connection `ssh -L localhost:local_port:localhost:server_port username:password@server_IP`.\n",
        "\n",
        "    3b.If your server asks for a password after ssh connection `ssh -L localhost:local_port:localhost:server_port username@server_IP`.\n",
        "4. Start the Jupyter notebook on the server_port you chose `jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --NotebookApp.port_retries=0 --notebook-dir=\"\" --no-browser --allow-root --NotebookApp.token='' --NotebookApp.disable_check_xsrf=True --port=server_port`.\n",
        "5. On another tab of your browser, check `localhost:local_port` to make sure the notebook has been correctly port forwarded.\n",
        "6. Select the drop-down menu for Colab runtimes in the top right of the notebook UI, 'Connect'.\n",
        "7. Select 'Connect to local runtime'.\n",
        "8. Enter `http://localhost:local_port/` into the pop-up window and select the 'Connect' button."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5oU-S9i-mkz",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Imports\n",
        "\n",
        "We now need to import some libraries that we will use to build the neural network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l92t8_-FOeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "!pip install online_triplet_loss\n",
        "from online_triplet_loss.losses import *\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "torch.multiprocessing.set_start_method('spawn')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpQfE1qVFUVW",
        "colab_type": "text"
      },
      "source": [
        "## Hardware Acceleration (GPU)\n",
        "\n",
        "Under 'Edit' -> 'Notebook Settings' make sure to select 'GPU' for Hardware Acceleration. The next block of code double-checks to make sure you've got GPU selected. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjVyWDJAF4-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egql6oG4BGpk",
        "colab_type": "text"
      },
      "source": [
        "##Loading data for training & testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrQFGF1T8wgI",
        "colab_type": "text"
      },
      "source": [
        "### Load your data via Google Drive (hosted runtime)\n",
        "\n",
        "There are a variety of ways to get your data into this notebook. The easiest are to upload directly, or to connect your Google Drive account. If you connect your Google Drive account, it will appear as a folder within the tray. You can right-click on a folder within your drive, copy the path, and then paste that into your code. Note that you'll have to delete the leading `/content/` from the path. \n",
        "\n",
        "**We are assuming that you have zipped a folder called `data` with two subfolders `testing` and `training`, and within each of those folders, one folder per class of _item_ you wish to train on/test.**\n",
        "\n",
        "**To upload** open the tray at left by clicking on the `>` button. Select 'Files' and then 'Upload'. You can then select a zip file from your machine. The tray does not refresh automatically, so you'll need to hit 'refresh' periodically.\n",
        "\n",
        "Then, unzip the data by running the next block. If you're using Google drive, skip to the next block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byy27-Z_EHgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If I'm uploading\n",
        "!unzip data.zip -d data/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp4KELeH9wcp",
        "colab_type": "text"
      },
      "source": [
        "**To mount your Google drive** run the next block of code. The results block will display a URL. Click on this, and a new window will open, confirming that you want to connect your drive. Once you've confirmed, an authorization code will be displayed. Copy this code, and paste into the results block. If all goes well, the results block will shortly display the text, 'Mounted at /content/drive'. Refresh the files pane in the tray at left, and you will see it there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne9mUU_TQFLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ft2c2VM-Zx7",
        "colab_type": "text"
      },
      "source": [
        "In the two blocks below, we show you how to copy a file from your drive to this space, how to make a new directory (`mkdir`) and how to unzip a folder into that new directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0rfcjBnQbVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you have data already on google drive\n",
        "# !cp \"drive/My Drive/one-shot-test/data_copy_with_equal_augs.zip\" data.zip\n",
        "!cp \"drive/My Drive/one-shot-test/data.zip\" data.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiy0t5z3J1Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload data from local machine then:\n",
        "# !mkdir data && unzip data.zip -d data/\n",
        "!unzip data.zip\n",
        "\n",
        "# Or copy it over from google drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRgIwYGu9qV_",
        "colab_type": "text"
      },
      "source": [
        "### Load your data locally (local runtime)\n",
        "\n",
        "**We are assuming that you have zipped a folder called `data` with two subfolders `testing` and `training`, and within each of those folders, one folder per class of _item_ you wish to train on/test.**\n",
        "\n",
        "You'll likely need to specify your own path below, ie. `path/to/your/data.zip`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvPOjTc6dgWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# https://thispointer.com/python-how-to-unzip-a-file-extract-single-multiple-or-all-files-from-a-zip-archive/\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('data.zip', 'r') as zipObj:\n",
        "    # Extract all the contents of zip file in current directory\n",
        "    zipObj.extractall('data')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0yyYaOq-031",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions\n",
        "\n",
        "Here we create three helper functions, `imshow` and `show_plot`, and `worker_init_fn`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE-TfRPnGGxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Is called when we want to show our compared images in the testing output\n",
        "def imshow(img, text=None, text2=None, should_save=False):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(\n",
        "            10, 10, text, style='italic', fontweight='bold',\n",
        "            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10})\n",
        "    if text2:\n",
        "        plt.text(\n",
        "            120, 10, text2, style='italic', fontweight='bold',\n",
        "            bbox={'facecolor': 'white', 'alpha': 0.8, 'pad': 10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Simple display function used to show loss during training\n",
        "def show_plot(iteration, loss):\n",
        "    plt.plot(iteration, loss)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OMg3RNu-QsV",
        "colab_type": "text"
      },
      "source": [
        "### Defining Dataloader workers' init()\n",
        "\n",
        "We specify an init function, `worker_init_fn` to split the task of generating anchor-unknown pairs among a group of workers. This function is provided as an argument for `DataLoader` class types, giving the dataloader an init method for its workers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dv5acBUGTpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def worker_init_fn(worker_id):\n",
        "    worker_info = torch.utils.data.get_worker_info()\n",
        "    dataset = worker_info.dataset\n",
        "\n",
        "    dataset.worker_unique_id = worker_info.id\n",
        "    dataset.number_of_workers = worker_info.num_workers\n",
        "    dataset.anchor_iter_index = torch.tensor(worker_info.id)\n",
        "    dataset.unknown_iter_index = torch.tensor(worker_info.id)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54yR3gxVEp3c",
        "colab_type": "text"
      },
      "source": [
        "##Custom classes\n",
        "\n",
        "Below we have our custom class definitions including our `Config` class, `SiameseNetworkDataset` classes, and our neural network's `SiameseNetwork` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hh2Y_l8_bpY",
        "colab_type": "text"
      },
      "source": [
        "### Configuration class\n",
        "\n",
        "We now create a class to configure some variables we will be reusing. \n",
        "\n",
        "You may want to change some of these variables to work for your purposes.\n",
        "\n",
        "Refer to the **'Loading Data' section for guidelines** for directory structure for your data.\n",
        "\n",
        "`training_dir = \"path/to/your/data/training`\n",
        "\n",
        "`testing_dir = \"path/to/your/data/testing`\n",
        "\n",
        "`num_generator_workers = desired_number_of_parallel_workers`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjIJqCwdy_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config():\n",
        "    training_dir = \"data/data/training\"\n",
        "    testing_dir = \"data/data/testing\"\n",
        "    train_batch_size = 32\n",
        "    train_number_epochs = 100\n",
        "    num_generator_workers = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC_2Oc5L_8V4",
        "colab_type": "text"
      },
      "source": [
        "### Dataset classes\n",
        "\n",
        "Under a superclass of `SiameseNetworkDataset`, two subclasses exist for different purposes; training and testing.\n",
        "\n",
        "For `PairwiseTrainingSiameseNetworkDataset`, we set up the code to generates a pair of images from our training dataset, 0 for geniune pair and 1 for imposter pair. It goes through the training directory, pairing images and assuming that images within a subfolder are similar and images from different subfolders are different. This is also where we attach filenames to the images so that when we are testing later we know which pairs of images we're dealing with. This addition to the original code, the class implementation now residing under `PairwiseTrainingSiameseNetworkDataset`, is courtesy of Tim Sherratt with modifications by Alex Lane.\n",
        "\n",
        "__Note:__ If the training dataset subdirectories do not have the same number of images in each subdirectory, `PairwiseTrainingSiameseNetworkDataset` will select pairs with more bias. Over a large number of pairs, more pairs containing images from subdirectories with less images will be generated. It is advised that the subdirectories have a uniform number of images within to ensure random selection.\n",
        "\n",
        "For `PairwiseTestingSiameseNetworkDatasetAnchors`, `__getitem__` returns a valid anchor while `PairwiseTestingSiameseNetworkDatasetUnknowns` returns a valid unknown together forming a valid anchor-unknown pair of images. Since the data is kept as a generator due to possibly working with large sets of data, the runtime should be __O(n^2)__ in our *Testing* section due to iteratively comparing each element of the dataset to each potential pair member in the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C49BrRm0GdTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "\n",
        "    def __init__(self, imageFolderDataset, transform=None, should_invert=True):\n",
        "        self.imageFolderDataset = imageFolderDataset\n",
        "        self.transform = transform\n",
        "        self.should_invert = should_invert\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)\n",
        "\n",
        "\n",
        "class TripletTrainingSiameseNetworkDataset(SiameseNetworkDataset):\n",
        "\n",
        "    # Returns an anchor image, a positive image (in the same class), and a \n",
        "    # negative image (in a different class)\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "\n",
        "        # First, we select a random image to be our anchor\n",
        "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "        #print(img0_tuple)\n",
        "\n",
        "        # Secondly, we select a random image in the same class as our positive\n",
        "        num_pos_images = (len(self.imageFolderDataset.imgs)\n",
        "            /len(self.imageFolderDataset.class_to_idx))\n",
        "        img1_tuple = self.imageFolderDataset.imgs[random.randrange((img0_tuple[1]*num_pos_images),((img0_tuple[1]+1)*num_pos_images))]\n",
        "\n",
        "        #Thirdly, we select a random image in a different class as the negative\n",
        "        size_first_neg_range = img0_tuple[1]*num_pos_images\n",
        "        size_second_neg_range = len(self.imageFolderDataset.imgs) - ((img0_tuple[1]+1)*num_pos_images)\n",
        "\n",
        "        total_random_neg_indices = size_first_neg_range+size_second_neg_range\n",
        "        neg_index_chosen = int(total_random_neg_indices * random.random())\n",
        "        if(neg_index_chosen < size_first_neg_range):\n",
        "            img2_tuple = self.imageFolderDataset.imgs[int(neg_index_chosen)]\n",
        "        else:\n",
        "            img2_tuple = self.imageFolderDataset.imgs[int(neg_index_chosen+num_pos_images)]\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img1 = Image.open(img1_tuple[0])\n",
        "        img2 = Image.open(img2_tuple[0])\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        img2 = img2.convert(\"L\")\n",
        "            \n",
        "        if self.should_invert:\n",
        "            img0 = PIL.ImageOps.invert(img0)\n",
        "            img1 = PIL.ImageOps.invert(img1)\n",
        "            img2 = PIL.ImageOps.invert(img2)\n",
        "\n",
        "        print(img0)\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        print(img0)\n",
        "        print(img0.shape)\n",
        "        '''\n",
        "        print(\"anchor\")\n",
        "        print(img0_tuple[0])\n",
        "        print(\"pos\")\n",
        "        print(img1_tuple[0])\n",
        "        print(\"neg\")\n",
        "        print(img2_tuple[0])\n",
        "        '''\n",
        "\n",
        "        return (img0,\n",
        "                img1,\n",
        "                img2,\n",
        "                img0_tuple[0],\n",
        "                img1_tuple[0],\n",
        "                img2_tuple[0])\n",
        "\n",
        "\n",
        "class BatchTripletSiameseNetworkDataset(SiameseNetworkDataset):\n",
        "\n",
        "    # Returns an anchor image, a positive image (in the same class), and a \n",
        "    # negative image (in a different class)\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # First, we select a random image to be our anchor\n",
        "        randIndex = random.randrange(0, len(self.imageFolderDataset.imgs))\n",
        "        img0_tuple = self.imageFolderDataset.imgs[randIndex]\n",
        "        #print(img0_tuple)\n",
        "\n",
        "        img0 = Image.open(img0_tuple[0])\n",
        "        img0 = img0.convert(\"L\")\n",
        "            \n",
        "        if self.should_invert:\n",
        "            img0 = PIL.ImageOps.invert(img0)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "        '''\n",
        "        print(\"anchor\")\n",
        "        print(img0_tuple[0])\n",
        "        print(\"pos\")\n",
        "        print(img1_tuple[0])\n",
        "        print(\"neg\")\n",
        "        print(img2_tuple[0])\n",
        "        '''\n",
        "\n",
        "        return (img0,\n",
        "                img0_tuple)\n",
        "\n",
        "\n",
        "class TripletTestingSiameseNetworkDataset(SiameseNetworkDataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            imageFolderDataset,transform,should_invert,\n",
        "            anchor_index,unknown_iter_index=0,\n",
        "            anchor_file_identifier='',\n",
        "            worker_unique_id=0,\n",
        "            number_of_workers=1):\n",
        "        super().__init__(imageFolderDataset,transform,should_invert)\n",
        "        self.anchor_iter_index = anchor_index\n",
        "        self.unknown_iter_index = unknown_iter_index\n",
        "        self.anchor_file_identifier = anchor_file_identifier\n",
        "        self.worker_unique_id = worker_unique_id\n",
        "        self.number_of_workers = number_of_workers\n",
        "\n",
        "    # Returns an anchor image, a positive image (in the same class), and a \n",
        "    # negative image (in a different class)\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #print(self.anchor_iter_index)\n",
        "        #print(\"before img0\")\n",
        "        img0_tuple = self.imageFolderDataset.imgs[self.anchor_iter_index.item()]\n",
        "        img1_tuple = self.imageFolderDataset.imgs[self.anchor_iter_index.item()]\n",
        "        #print(self.anchor_iter_index)\n",
        "        #print(type(img0_tuple))\n",
        "        #print(img0_tuple)\n",
        "        #print(\"after img0\")\n",
        "\n",
        "        # Secondly, we select a random image in the same class as our positive\n",
        "        #print(\"before img1\")\n",
        "        #img1 = generate_positive(img0_tuple)\n",
        "        #print(type(img1))\n",
        "        #print(img1)\n",
        "        #print(\"after img1\")\n",
        "\n",
        "        #print(self.imageFolderDataset.class_to_idx)\n",
        "              \n",
        "        while self.unknown_iter_index < len(self):\n",
        "            if (\n",
        "                    not self.anchor_file_identifier \n",
        "                    in self.imageFolderDataset.imgs[self.unknown_iter_index][0]\n",
        "                ):\n",
        "                img2_tuple = (\n",
        "                    self.imageFolderDataset.imgs[self.unknown_iter_index])\n",
        "                break\n",
        "            else:\n",
        "                self.unknown_iter_index += self.number_of_workers\n",
        "\n",
        "        if self.unknown_iter_index >= len(self):\n",
        "            self.unknown_iter_index = 0\n",
        "            return -1, self.worker_unique_id, -1, -1, -1, -1, -1\n",
        "        else:\n",
        "            self.unknown_iter_index += self.number_of_workers\n",
        "\n",
        "            #print(img0_tuple[0])\n",
        "            #print(img1_tuple[0])\n",
        "            img1 = generate_positive(img1_tuple[0])\n",
        "\n",
        "            img0 = Image.open(img0_tuple[0])\n",
        "            #img1 = Image.open(img1)\n",
        "            img2 = Image.open(img2_tuple[0])\n",
        "            img0 = img0.convert(\"L\")\n",
        "            img1 = img1.convert(\"L\")\n",
        "            img2 = img2.convert(\"L\")\n",
        "            \n",
        "            if self.should_invert:\n",
        "                img0 = PIL.ImageOps.invert(img0)\n",
        "                img1 = PIL.ImageOps.invert(img1)\n",
        "                img2 = PIL.ImageOps.invert(img2)\n",
        "\n",
        "            if self.transform is not None:\n",
        "                img0 = self.transform(img0)\n",
        "                img1 = self.transform(img1)\n",
        "                img2 = self.transform(img2)\n",
        "            '''\n",
        "            print(\"anchor\")\n",
        "            print(img0_tuple[0])\n",
        "            print(\"pos\")\n",
        "            print(img1_tuple[0])\n",
        "            print(\"neg\")\n",
        "            print(img2_tuple[0])\n",
        "            '''\n",
        "\n",
        "            return (self.anchor_iter_index,\n",
        "                    self.worker_unique_id,\n",
        "                    img0, \n",
        "                    img1,\n",
        "                    img2,  \n",
        "                    img0_tuple[0],\n",
        "                    img2_tuple[0])\n",
        "\n",
        "\n",
        "class PairwiseTestingSiameseNetworkDatasetAnchors(SiameseNetworkDataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            imageFolderDataset,\n",
        "            transform, should_invert,\n",
        "            anchor_iter_index,\n",
        "            unknown_iter_index=0,\n",
        "            anchor_file_identifier='',\n",
        "            worker_unique_id=0,\n",
        "            number_of_workers=1):\n",
        "        super().__init__(imageFolderDataset, transform, should_invert)\n",
        "        self.anchor_iter_index = anchor_iter_index\n",
        "        self.unknown_iter_index = unknown_iter_index\n",
        "        self.anchor_file_identifier = anchor_file_identifier\n",
        "        self.worker_unique_id = worker_unique_id\n",
        "        self.number_of_workers = number_of_workers\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        while self.anchor_iter_index < len(self):\n",
        "            if (\n",
        "                    self.anchor_file_identifier\n",
        "                    in\n",
        "                    self.imageFolderDataset.imgs[self.anchor_iter_index][0]):\n",
        "                anchor_tuple = (\n",
        "                    self.imageFolderDataset.imgs[self.anchor_iter_index])\n",
        "                break\n",
        "            else:\n",
        "                self.anchor_iter_index += self.number_of_workers\n",
        "\n",
        "        if self.anchor_iter_index >= len(self):\n",
        "            return -1, -1, -1, -1, -1, -1\n",
        "        else:\n",
        "            self.anchor_iter_index += self.number_of_workers\n",
        "            anchor_image = Image.open(anchor_tuple[0])\n",
        "            anchor_image = anchor_image.convert(\"L\")\n",
        "\n",
        "            if self.should_invert:\n",
        "                anchor_image = PIL.ImageOps.invert(anchor_image)\n",
        "\n",
        "            if self.transform is not None:\n",
        "                anchor_image = self.transform(anchor_image)\n",
        "\n",
        "            return (self.anchor_iter_index-self.number_of_workers,\n",
        "                    self.worker_unique_id,\n",
        "                    anchor_image,\n",
        "                    -1,\n",
        "                    anchor_tuple[0],\n",
        "                    -1)\n",
        "\n",
        "\n",
        "class PairwiseTestingSiameseNetworkDatasetUnknowns(SiameseNetworkDataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            imageFolderDataset, transform, should_invert,\n",
        "            anchor_iter_index, unknown_iter_index=0,\n",
        "            anchor_file_identifier='',\n",
        "            worker_unique_id=0,\n",
        "            number_of_workers=1):\n",
        "        super().__init__(imageFolderDataset, transform, should_invert)\n",
        "        self.anchor_iter_index = anchor_iter_index\n",
        "        self.unknown_iter_index = unknown_iter_index\n",
        "        self.anchor_file_identifier = anchor_file_identifier\n",
        "        self.worker_unique_id = worker_unique_id\n",
        "        self.number_of_workers = number_of_workers\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        anchor_tuple = self.imageFolderDataset.imgs[self.anchor_iter_index]\n",
        "\n",
        "        while self.unknown_iter_index < len(self):\n",
        "            if (\n",
        "                    self.anchor_file_identifier\n",
        "                    in self.imageFolderDataset.imgs[self.unknown_iter_index][0]\n",
        "                    ):\n",
        "                self.unknown_iter_index += self.number_of_workers\n",
        "            else:\n",
        "                unknown_tuple = (\n",
        "                    self.imageFolderDataset.imgs[self.unknown_iter_index])\n",
        "                break\n",
        "\n",
        "        if self.unknown_iter_index >= len(self):\n",
        "            return -1, self.worker_unique_id, -1, -1, -1, -1\n",
        "        else:\n",
        "            self.unknown_iter_index += self.number_of_workers\n",
        "\n",
        "            anchor_image = Image.open(anchor_tuple[0])\n",
        "            unknown_image = Image.open(unknown_tuple[0])\n",
        "            anchor_image = anchor_image.convert(\"L\")\n",
        "            unknown_image = unknown_image.convert(\"L\")\n",
        "\n",
        "            if self.should_invert:\n",
        "                anchor_image = PIL.ImageOps.invert(anchor_image)\n",
        "                unknown_image = PIL.ImageOps.invert(unknown_image)\n",
        "\n",
        "            if self.transform is not None:\n",
        "                anchor_image = self.transform(anchor_image)\n",
        "                unknown_image = self.transform(unknown_image)\n",
        "\n",
        "            return (self.unknown_iter_index,\n",
        "                    self.worker_unique_id,\n",
        "                    anchor_image,\n",
        "                    unknown_image,\n",
        "                    anchor_tuple[0],\n",
        "                    unknown_tuple[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoUIsQJ5BpZp",
        "colab_type": "text"
      },
      "source": [
        "### Neural Network class\n",
        "\n",
        "We will use a standard convolutional neural network. Each convolutional layer has batch normalisation and then dropout. As Gupta says, 'There is nothing special about this network. It accepts an input of 100px by 100px and has 3 full connected layers after the convolution layers'. This might be where you want to experiment, eventually, with adding more layers and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GnJJ-CSe9VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(1, 4, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(4),\n",
        "            \n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(4, 8, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(8, 8, kernel_size=3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(8),\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(8*100*100, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(500, 500),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(500, Config.train_batch_size))\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2, training=True):\n",
        "        if training:\n",
        "            output1 = self.forward_once(input1)\n",
        "            return output1\n",
        "        else:\n",
        "            output1 = self.forward_once(input1)\n",
        "            output2 = self.forward_once(input2)\n",
        "            return output1, output2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k0ZQeUoA3-C",
        "colab_type": "text"
      },
      "source": [
        "## Setting the image folder to be used by the custom dataset\n",
        "\n",
        "In the first block, we specify the location of the training data. In the second block, we pass the images through the custom dataset class,  resizing them to 100 x 100 pixels, transforming them into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gAhHc3_A3ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
        "# print(folder_dataset.imgs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqQBMCGIKdsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "triplet_siamese_dataset = BatchTripletSiameseNetworkDataset(\n",
        "    imageFolderDataset=folder_dataset,\n",
        "    transform=transforms.Compose([transforms.Resize((100,100)),\n",
        "                                  transforms.ToTensor()]),\n",
        "    should_invert=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_KJxHsaBfU0",
        "colab_type": "text"
      },
      "source": [
        "## Visualising some of the training data\n",
        "\n",
        "The top row and the bottom row of any column is one pair. The 0s and 1s correspond to the column of the image. 1 indiciates dissimilar, and 0 indicates similar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVBSCKdIKhFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "vis_dataloader = DataLoader(\n",
        "    pairwise_siamese_dataset, shuffle=True, num_workers=1, batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "example_batch = next(dataiter)\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]), 0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYNqH02sHdlU",
        "colab_type": "text"
      },
      "source": [
        "##Create or load model\n",
        "\n",
        "You can train the neural network from scratch if you'd like, or alternatively load a pre-existing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iFjQUx_QeJRn"
      },
      "source": [
        "### Training the neural network\n",
        "\n",
        "The next three blocks configure all of the variables and settings for training the neural network. You might want to experiment with changing the values of the Adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or4xt6VDKp2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataloader = DataLoader(\n",
        "    triplet_siamese_dataset,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    batch_size=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnRiUE3nKuqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "net = net.to(device)\n",
        "criterion = batch_hard_triplet_loss\n",
        "optimizer = optim.Adam(net.parameters(),lr = 0.00006, betas=(0.9,0.999), eps=1e-8 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04O3bd3SCiXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = []\n",
        "loss_history = []\n",
        "iteration_number = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7YqWETMC1Zl",
        "colab_type": "text"
      },
      "source": [
        "#### Start the training\n",
        "\n",
        "This next block will start the training for the number of epochs set at the start of the notebook in the configuration block. The code is slightly modified so that filenames get stored for the images. Approximately half of our anchor-unknown pairs will be anchor-positive and anchor-negative pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA0y-hd7K5et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_generator = iter(train_dataloader)\n",
        "for epoch in range(0,Config.train_number_epochs):\n",
        "    batch_tensor = torch.Tensor(0,Config.train_batch_size).to(device)\n",
        "    batch_labels = torch.Tensor(0,).to(device)\n",
        "    selected_images = []\n",
        "    for i in range(0, Config.train_batch_size):\n",
        "        while(True):\n",
        "            #https://github.com/amdegroot/ssd.pytorch/issues/214\n",
        "            try:\n",
        "                potential_batch_sample, potential_name = next(batch_generator)\n",
        "            except StopIteration:\n",
        "                batch_generator = iter(train_dataloader)\n",
        "                potential_batch_sample, potential_name = next(batch_generator)\n",
        "            if (potential_name[0] in selected_images):\n",
        "                continue\n",
        "            else:\n",
        "                selected_images.append(potential_name[0])\n",
        "\n",
        "                batch_sample = potential_batch_sample\n",
        "                batch_sample = batch_sample.cuda()\n",
        "\n",
        "                potential_name = potential_name[1].cuda()\n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                batch_sample_embed = net(batch_sample, _)\n",
        "\n",
        "                batch_tensor = torch.cat((batch_tensor, batch_sample_embed), 0)\n",
        "                batch_labels = torch.cat((batch_labels, potential_name.float()), 0)\n",
        "                break\n",
        "\n",
        "    batch_tensor = batch_tensor.cuda()\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    hard_triplet_loss = criterion(batch_labels, batch_tensor, margin=2.0, device=device)\n",
        "    hard_triplet_loss.backward()\n",
        "    optimizer.step()\n",
        "    print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch, \n",
        "                                                       hard_triplet_loss.item()))\n",
        "    iteration_number += 10\n",
        "    counter.append(iteration_number)\n",
        "    loss_history.append(hard_triplet_loss.item())\n",
        "show_plot(counter, loss_history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKVPWER5DJVS",
        "colab_type": "text"
      },
      "source": [
        "#### Save the model\n",
        "\n",
        "The block below saves the state dictionary, and the model. This is handy so that once you *have* a trained model, you can return to it if your notebook connection to Colab is broken, or if you have to set the project aside for a while. The second block copies (`cp`) the file to a location on Google drive. You can also download the file to your machine directly by right-clicking the filename in the tray at left (you might need to hit 'refresh' to see it, first)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTopDCEhyy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the model!\n",
        "torch.save(net.state_dict(), 'net_params_new.pkl')\n",
        "torch.save(net, 'net.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2QLT90P6eNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp net_params.pkl \"drive/My Drive/one-shot-test\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sizl8QETDvAg",
        "colab_type": "text"
      },
      "source": [
        "### Loading a model\n",
        "\n",
        "If this is your first time through the notebook, you don't need to worry about this; skip down to 'Testing'. If you're returning to the project, make sure\n",
        "+ that you've got hardware acceleration turned on\n",
        "+ that you've run all of the code again to import the necessary libraries, and set the various configurations \n",
        "  + _including_ the SiameseNetwork class\n",
        "\n",
        "The block below assumes you've connected Google drive. Alternatively you can upload directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCbuAtMOigQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model back from your drive\n",
        "!cp \"drive/My Drive/one-shot-test/net_params.pkl\" net_params.pkl\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLQ_aEcCERPI",
        "colab_type": "text"
      },
      "source": [
        "...then tell the machine to load the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvKhEPhr7oqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the model\n",
        "net = SiameseNetwork()\n",
        "net.load_state_dict(torch.load('net_params.pkl'))\n",
        "dp = nn.DataParallel(net)  # https://github.com/pytorch/pytorch/issues/3805\n",
        "\n",
        "# The incompatiblekeys message might not be an issue - see\n",
        "# https://gpytorch.readthedocs.io/en/latest/examples/00_Basic_Usage/Saving_and_Loading_Models.html\n",
        "# which replicates that incompatiblekeys message without any kind of comment,\n",
        "# seems to be hunkydory\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LLQYb1LErDI",
        "colab_type": "text"
      },
      "source": [
        "## Testing\n",
        "\n",
        "This block iteratively loads pairs of images with known provenance versus unknown provenance from different subfolders in your testing folder. It then compares the results of these anchor-unknown pairs using euclidean distance. It will print out the images with the dissimilarity distance, as well as printing out the filenames for each pair. You can experiment with printing these results to a file.\n",
        "\n",
        "Since this code currently outputs all anchor-unknown pairs, the runtime is __O(n^2)__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA4QpoRCLgSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Time code snippet\n",
        "# https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution\n",
        "start_time = time.time()\n",
        "\n",
        "# Init variable representing testing data's directory,\n",
        "# see Config section to specify path\n",
        "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
        "\n",
        "# Create the dataset, pairwise_siamese_dataset_anchors, with data from the\n",
        "# testing data\n",
        "# Then, create a generator with pairwise_siamese_dataset-unknowns\n",
        "pairwise_siamese_dataset_anchors = PairwiseTestingSiameseNetworkDatasetAnchors(\n",
        "    imageFolderDataset=folder_dataset_test,\n",
        "    transform=transforms.Compose(\n",
        "        [transforms.Resize((100, 100)), transforms.ToTensor()]),\n",
        "    should_invert=False,\n",
        "    anchor_iter_index=0,\n",
        "    anchor_file_identifier='ref-')\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    pairwise_siamese_dataset_anchors,\n",
        "    num_workers=Config.num_generator_workers,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    worker_init_fn=worker_init_fn)\n",
        "\n",
        "generator_anchor_images = iter(test_dataloader)\n",
        "workers_terminated_outer = np.zeros(Config.num_generator_workers)\n",
        "\n",
        "# Outer loop searches for anchors\n",
        "for i in range(len(generator_anchor_images)):\n",
        "\n",
        "    \n",
        "    # Returns a found anchor's index, image, and filepath\n",
        "    anchor_index, worker_id_outer, anchor_image, _, anchor_filepath, _ = next(\n",
        "        generator_anchor_images)\n",
        "\n",
        "    '''\n",
        "    # Stop outer loop if index is out of bounds, no more potential anchors\n",
        "    if not(0 in workers_terminated_outer):\n",
        "        break\n",
        "    '''\n",
        "\n",
        "    if anchor_index.item() < 0:\n",
        "        '''\n",
        "        np.put(workers_terminated_outer, worker_id_outer, 1)\n",
        "        if not(0 in workers_terminated_outer):\n",
        "            break\n",
        "        '''\n",
        "        break\n",
        "    else:\n",
        "\n",
        "        # Create new dataset with a given known anchor's index\n",
        "        # Then, create a generator with pairwise_siamese_dataset-unknowns\n",
        "        pairwise_siamese_dataset_unknowns = (\n",
        "            PairwiseTestingSiameseNetworkDatasetUnknowns(\n",
        "            imageFolderDataset=folder_dataset_test,\n",
        "            transform=transforms.Compose([transforms.Resize((100, 100)),\n",
        "                                          transforms.ToTensor()]),\n",
        "            should_invert=False,\n",
        "            anchor_iter_index=anchor_index,\n",
        "            anchor_file_identifier='ref-'))\n",
        "\n",
        "        compare_dataloader = test_dataloader = DataLoader(\n",
        "            pairwise_siamese_dataset_unknowns,\n",
        "            num_workers=Config.num_generator_workers,\n",
        "            batch_size=1, shuffle=False,\n",
        "            worker_init_fn=worker_init_fn)\n",
        "\n",
        "        generator_unknown_prov_images = iter(compare_dataloader)\n",
        "        workers_terminated_inner = np.zeros(Config.num_generator_workers)\n",
        "\n",
        "        # Inner loop pairs known anchor with every image of unknown provenance\n",
        "        for k in range(len(generator_unknown_prov_images)):\n",
        "\n",
        "            # no_more_unknowns will return -1 if all pairs have been found\n",
        "            no_more_unknowns, worker_id_inner, _, unknown_prov_image, _, (\n",
        "                unknown_prov_filepath) = (next(generator_unknown_prov_images))\n",
        "\n",
        "            '''\n",
        "            # Stop this inner loop if all anchor-unknown pairs for the current\n",
        "            # anchor image are found\n",
        "            if not(0 in workers_terminated_inner):\n",
        "                break\n",
        "            '''\n",
        "\n",
        "            if no_more_unknowns.item() < 0:\n",
        "                '''\n",
        "                np.put(workers_terminated_inner, worker_id_inner, 1)\n",
        "                if not(0 in workers_terminated_inner):\n",
        "                    break\n",
        "                '''\n",
        "                break\n",
        "            else:\n",
        "                concatenated = torch.cat((anchor_image, unknown_prov_image), 0)\n",
        "\n",
        "                anchor_embedding, unknown_embedding = net(\n",
        "                    Variable(anchor_image).cuda(),\n",
        "                    Variable(unknown_prov_image).cuda(), training=False)\n",
        "\n",
        "                euclidean_distance = F.pairwise_distance(\n",
        "                    anchor_embedding, unknown_embedding)\n",
        "                cosine_similarity = F.cosine_similarity(anchor_embedding, unknown_embedding)\n",
        "\n",
        "                # Show the images:\n",
        "                imshow(\n",
        "                    torchvision.utils.make_grid(concatenated),\n",
        "                    'Euclidean Distance: {:.2f}'.format(euclidean_distance.item()),\n",
        "                    'Cosine Similarity: {:.4f}'.format(cosine_similarity.item()))\n",
        "\n",
        "                # Show the paths for the two images\n",
        "                print('Image 1: {}'.format(anchor_filepath[0]))\n",
        "                print('Image 2: {}'.format(unknown_prov_filepath[0]))\n",
        "                print('Dissimilarity: {:.2f}'.format(\n",
        "                    euclidean_distance.item()))\n",
        "\n",
        "print('Finshed all anchor-unknown pair comparisons')\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVt-evEFFP62",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# The End\n",
        "\n",
        "The two code blocks below print out the structure of the neural network, and the version info of all of the loaded packages in this environment. This information is useful for replicating this notebook in the future.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDnSSRJpUuzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models\n",
        "model = net\n",
        "print(model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2x_rKjj7UxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# watermark is not installed by default.\n",
        "# the first time through, uncomment the two lines below\n",
        "# then run the block.\n",
        "#\n",
        "#\n",
        "# !pip install watermark\n",
        "# %load_ext watermark\n",
        "%watermark -v -m -p numpy, scipy, torchvision, PIL, tensorflow, torch -g\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}